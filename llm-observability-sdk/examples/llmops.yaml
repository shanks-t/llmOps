# LLM Ops SDK Configuration for Examples
#
# This configuration file is used by the example server.
#
# Usage:
#   import llmops
#   llmops.init(config_path="examples/llmops.yaml")

# Service identification
service:
  name: "llmops-demo"
  version: "1.0.0"

# Backend selection: "phoenix" or "mlflow"
# Can be overridden via LLMOPS_BACKEND environment variable
backend: phoenix

# Phoenix backend configuration (OpenInference semantic conventions)
phoenix:
  endpoint: http://localhost:6006/v1/traces

# MLflow backend configuration (OTLP-based tracing for Google ADK)
mlflow:
  tracking_uri: http://localhost:5001

# Debug settings
debug:
  # Print traces to console for debugging
  console: false

# TODO: Privacy settings
# privacy:
  # Capture input/output content in traces
  # capture_content: true

# Auto-instrumentation settings
auto_instrumentation:
  enabled: true
